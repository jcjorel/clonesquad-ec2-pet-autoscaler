#!/usr/bin/python3
"""This application is designed to run on instances managed by CloneSquad.

It is a daemon that polls efficiently the CloneSquad API Gateway and detect status change. 
On status change, it starts scripts to perform actions.

It also contains a common default action that can be enabled optionnaly:
* Ability to set IPTable entries on 'draining' state to block new incoming connection to
user specified port list.

"""

import os
import sys
import argparse
import json
import subprocess
import re
import pdb
import time
import glob
from datetime import datetime, timezone

# Configure logging
import logging
from logging import handlers
LOG_LEVEL = logging.INFO
logger = logging.getLogger(sys.argv[0])
logger.setLevel(LOG_LEVEL)
logger.propagate = False
ch = logging.StreamHandler()
ch.setLevel(LOG_LEVEL)
logger_formatter = logging.Formatter("[%(levelname)s] %(asctime)s %(filename)s:%(lineno)d - %(message)s")
ch.setFormatter(logger_formatter)
logger.addHandler(ch)

try:
    import requests
except:
    logger.error("Missing critical dependency! Please do 'python3 -m pip install requests requests-iamauth boto3'...")
    sys.exit(1)
try:
    from iamauth import IAMAuth
except:
    logger.error("Missing critical dependency! Please do 'python3 -m pip install requests requests-iamauth boto3'...")
    sys.exit(1)
try:
    import boto3
    from botocore.config import Config
except:
    logger.error("Missing critical dependency! Please do 'python3 -m pip install requests requests-iamauth boto3'...")
    sys.exit(1)

def sys_exec(cmd, silent=False):
    try:
        if not silent:
            logger.info("Exec command: %s" % " ".join(cmd))
        res = subprocess.Popen(cmd, stdout=subprocess.PIPE)
        res.wait() 
    except OSError:
        logger.exception(f"Failed to execute command: {cmd}")
        return None

    if res.returncode != 0:
        logger.error("Executed command %s return a non-zero code: %s" % (cmd, res.returncode))
        return None   
    return str(res.stdout.read(), "utf-8")


def on_draining_block_new_connections_to_ports(instance_state, excluded):
    if os.getuid() != 0:
        return
    ports  = args["on_draining_block_new_connections_to_ports"]

    if args["instance_state"] != "":
        instance_state = args["instance_state"] # Override
    if instance_state not in ["stopping", "draining"] and not excluded:
        if len(ports):
            logger.info("on_draining_block_new_connections_to_ports: Instance not in 'draining' or 'stopping' "
                f"state (current state is '{instance_state}'): No port blacklist.")
        ports = [] # When not in draining state, no port are blacklisted
    else:
        logger.info(f"Configuring 'on_draining_block_new_connections_to_ports' built-in behavior for ports (excluded={excluded}): {ports}")

    # Always run an 'iptables -L' to ensure iptables kernel modules are loaded.
    sys_exec(["iptables", "-L"], silent=True)
    output = sys_exec(["iptables-save"], silent=True)
    if output is None:
        logger.error("Failed to retrieve iptables-save!")
        return
    iptables          = output.split("\n")
    filter_start_idx  = -1
    filter_commit_idx = -1
    for i in range(0, len(iptables)):
        if iptables[i] == "*filter":
            filter_start_idx = i
        if filter_start_idx != -1 and iptables[i] == "COMMIT":
            filter_commit_idx = i
            break
    if filter_start_idx == -1 or filter_commit_idx == -1:
        logger.error("Can't find '*filter' and/or 'COMMIT' keyword in iptables-save output!")
        return
    filter_table = iptables[filter_start_idx:filter_commit_idx]

    cs_chain_pattern = ":CS-INSTANCE-WATCHER -"
    cs_chain         = next(filter(lambda l: l.startswith(cs_chain_pattern), filter_table), None)
    if len(ports) and cs_chain is None:
        sys_exec(["iptables", "-N", "CS-INSTANCE-WATCHER"])

    send_cs_chain_pattern = "-A INPUT -j CS-INSTANCE-WATCHER"
    send_cs_chain         = next(filter(lambda l: l.startswith(send_cs_chain_pattern), iptables), None)
    if len(ports) and send_cs_chain is None:
        sys_exec(["iptables", "-I", "INPUT", "-j", "CS-INSTANCE-WATCHER"])
    
    rule_pattern   = "-{command} CS-INSTANCE-WATCHER -p tcp -m tcp --dport {port} -m state --state NEW -j REJECT --reject-with icmp-port-unreachable"
    match_var      = {"command":"A", "port":"(\d+)"}
    cs_rules       = [r for r in filter_table if re.match(rule_pattern.format(**match_var), r)]
    existing_ports = []
    for rule in cs_rules:
        m = re.search(rule_pattern.format(**match_var), rule)
        if len(m.groups()) != 1:
            logger.error("Can't parse rule '%s' as expected! Bug??" % rule)
            continue
        existing_ports.append(int(m.group(1)))

    # Remove outdated rules
    outdated_ports = [ r for r in existing_ports if r not in ports ]
    for p in outdated_ports:
        cmd = "iptables %s" % rule_pattern.format(**{"command":"D", "port":p})
        sys_exec(cmd.split())
    # Add missing rules
    missing_ports  = [ r for r in ports if r not in existing_ports ]
    for p in missing_ports:
        cmd = "iptables %s" % rule_pattern.format(**{"command":"A", "port":p})
        sys_exec(cmd.split())

    # If no port configured, suppress also the chain
    if not len(ports):
        if send_cs_chain is not None:
            sys_exec(["iptables", "-D", "INPUT", "-j", "CS-INSTANCE-WATCHER"])
        if cs_chain is not None:
            sys_exec(["iptables", "-X", "CS-INSTANCE-WATCHER"])

COUNT=0
last_instance_state = None
def loop():
    global COUNT
    global last_instance_state
    start_time = seconds()

    read_configuration()

    session    = requests.Session()
    try:
        instance_id = str(session.get('http://169.254.169.254/latest/meta-data/instance-id').content, "utf-8")
    except Exception as e:
        logger.exception(f"Failed to fetch current instance Id! (???) : {e}")
        return False
    logger.info(f"Running on instance '{instance_id}'.")
    try:
        os.environ["AWS_DEFAULT_REGION"] = str(session.get('http://169.254.169.254/latest/meta-data/placement/availability-zone').content, "utf-8")[:-1]
    except Exception as e:
        logger.error(f"Failed to fetch current region Id! (???) : {e}")
        return False
    logger.info("Current region: %s" % os.environ["AWS_DEFAULT_REGION"])
    session.auth = IAMAuth() # Make out calls capable to do SigV4 auth.

    config = Config(
       retries = {
       'max_attempts': 5,
       'mode': 'standard'
       })
    sts_client    = boto3.client("sts",    config=config)
    ec2_client    = boto3.client("ec2",    config=config)
    lambda_client = boto3.client("lambda", config=config)

    # Discover the current CloneSquad GroupName
    try:
        Filters   = [{'Name': 'instance-id', 'Values': [instance_id]}]
        response  = ec2_client.describe_instances(Filters=Filters)
        instances = []
        for reservation in response["Reservations"]:
            instances.extend(reservation["Instances"])
        if len(instances) != 1:
            raise Exception(f"Can't describe instance '{instance_id}'! (describe_instances returned %d instances)" % len(instances))
    except Exception as e:
        logger.error(f"Failed to describe instance '{instance_id}' (IAM role issue?)! : {e}")
        return False

    tags       = instances[0]["Tags"]
    tag        = next(filter(lambda t: t["Key"] == "clonesquad:group-name", tags), None)
    if tag is None:
        logger.error(f"Instance '{instance_id}' does not belong to a CloneSquad group! (No 'clonesquad:group-name' tag!)")
        return False
    group_name = tag["Value"]

    # Get the current Account Id
    try:
        account_id = sts_client.get_caller_identity().get('Account')
    except Exception as e:
        logger.error(f"Failed to get current Account Id from STS service (IAM role issue?)! : {e}")
        return False

    # Discover API GW URL
    try:
        response   = lambda_client.invoke(
            FunctionName="arn:aws:lambda:%s:%s:function:CloneSquad-Discovery-%s" % (os.environ["AWS_DEFAULT_REGION"], account_id, group_name),
            InvocationType='RequestResponse',
            LogType='Tail',
            Payload=b""
            )
        payload          = json.loads(str(response["Payload"].read(), "utf-8"))
        logger.info(f"Discovery data: {payload}")
        api_gw_url       = payload["InteractAPIGWUrl"]
        api_gw_id        = payload["InteractApi"]
        vpc_endpoint_dns = payload["ApiGwVpcEndpointDNSEntry"] if "ApiGwVpcEndpointDNSEntry" in payload and payload["ApiGwVpcEndpointDNSEntry"] != "" else None
    except Exception as e:
        logger.error(f"Failed to discover API GW Url!  (IAM role issue?): {e}")
        return False

    while (seconds() - start_time) < args["stale_context_timeout"]:
        last_poll_time = seconds()
        try:
            if vpc_endpoint_dns is not None:
                # If a VPC Endpoint is specified, we prefer it...
                url = "https://%s/v1/metadata" % vpc_endpoint_dns
            else:
                # If not, we use the Public DNS name of the API GW.
                url = "%s/metadata" % api_gw_url
            logger.info(f"Calling API GW URL {url}...")
            api_payload = str(session.get(url, headers={"x-apigw-api-id": f"{api_gw_id}"}).content, "utf-8")
            if api_payload[0] != "{":
                raise ValueError(f"API GW Response not a JSON: '{api_payload}'")
            payload     = json.loads(api_payload)
            if "State" not in payload:
                raise ValueError(f"API GW Response not in an expected JSON format: '{api_payload}'")
        except:
            logger.error(f"Failed to process API GW response! ({url}) [API response={api_payload}]")
            return False
        logger.info(f"Instance metadata: {payload}")
        subfleet_name  = payload["SubfleetName"]

        wait_time = max(1, min(60, args["api_polling_period"]) - (seconds() - last_poll_time))

        # When targetgroups are used, we do not need cs-instance-watcher (only in the autoscaled fleet, we always need in subfleet).
        if subfleet_name is None and "TargetGroups" in payload:
            targetgroups = payload["TargetGroups"]
            if targetgroups["NbOfTargetGroups"] and not args["force"]:
                logger.warning(f"Targetgroups are used in group name '{group_name}': No need for cs-instance-watcher! (To force use, set --force option)")
                time.sleep(wait_time)
                return False

        instance_state = payload["State"]
        #if COUNT >= 2: instance_state = "draining"
        #COUNT += 1

        # Call built-in behavior
        tag_excluded       = next(filter(lambda t: t["Key"] == "clonesquad:excluded", tags), None)
        tag_force_excluded = next(filter(lambda t: t["Key"] == "clonesquad:force-excluded-instance-in-targetgroups", tags), None)
        excluded = False
        if (("Excluded" in payload and payload["Excluded"] in ["True", "true"]) or 
            (tag_excluded is not None and tag_excluded["Value"] in ["True", "true"])):
            logger.info("Detected instance tag 'clonesquad:excluded' with 'True' value!")
            if tag_force_excluded is not None and tag_force_excluded["Value"] in ["True", "true"]:
                logger.info("Detected instance tag 'clonesquad:force-excluded-instance-in-targetgroups' with 'True' value! Ignoring exclusion directive!")
            else:
                excluded = True
        on_draining_block_new_connections_to_ports(instance_state, excluded)

        # React to instance state change
        if instance_state != last_instance_state and last_instance_state is not None:
            script_dir = f"%s/{instance_state}" % args["script_dir"]
            logger.info(f"State changed from '{last_instance_state}' to '{instance_state}'. Looking at directory '{script_dir}' for scripts to launch...")
            for script in glob.glob(f"{script_dir}/*"):
                if os.path.isfile(script):
                    try:
                        logger.info(f"{script}: %s" % sys_exec([script, instance_state, last_instance_state]))
                    except Exception as e:
                        logger.error(f"Got an Exception while starting '{script}'! : {e}")
        last_instance_state = instance_state

        logger.info("Waiting next polling (%.02fs)..." % wait_time)
        time.sleep(wait_time)

def seconds():
    now   = datetime.now(tz=timezone.utc) 
    epoch = datetime.utcfromtimestamp(0).replace(tzinfo=timezone.utc)
    return (now - epoch).total_seconds()

args         = None
default_args = {
    "api_polling_period": 5,
    "on_draining_block_new_connections_to_ports": [],
    "instance_state": "",
    "stale_context_timeout": 30,
    "config": "/etc/cs-instance-watcher.json",
    "script_dir": "/etc/cs-instance-watcher.d",
    "force": False
}

def read_configuration():
    global args
    first_pass = args is None
    args       = default_args.copy()
    if os.path.exists(args["config"]):
        try:
            c = json.load(args["config"])
            for a in c:
                args[a] = c[a]
        except Exception as e:
            logger.error("Failed to read/parse configuration file '%s'! : %s" % (args["config"], e))
            sys.exit(1)

    # Override with command line args
    _args = parser.parse_args()._get_kwargs()
    for a in _args:
        args[a[0]] = a[1]

    generate_systemd        = next(filter(lambda a: a[0] == "generate_systemd", _args), None)
    do_not_generate_systemd = next(filter(lambda a: a[0] == "do_not_generate_systemd", _args), None)
    if generate_systemd and not do_not_generate_systemd:
        cmd = sys.argv[0]
        options = "%s --do-not-generate-systemd" % " ".join(sys.argv[1:])
        with open(generate_systemd[1], "w") as f:
            f.write(f"""
[Unit]
Description=CloneSquad Instance service
After=network.target
StartLimitIntervalSec=0

[Service]
Type=simple
Restart=always
RestartSec=10
ExecStart={cmd} {options}

[Install]
WantedBy=multi-user.target
            """)
        logger.info("Generated systemd file at '%s'." % generate_systemd[1])
        sys.exit(0)

    if first_pass:
        log_file = next(filter(lambda a: a[0] == "log_file", _args), None)
        if log_file and log_file[1] is not None:
            rotate_params = ["h", "1", "24"] # Default value for log rotate
            log_file_rotate = next(filter(lambda a: a[0] == "log_file_rotate", _args), None)
            if log_file_rotate:
                params = log_file_rotate[1].split(",")
                for i in range(0, len(params)):
                    rotate_params[i] = params[i]
            logger.info(f"Logging to rotated file '%s' (rotation parameters={rotate_params}). Disabling logging to stdout..." % log_file[1])
            logger.removeHandler(logger.handlers[0])
            handler = handlers.TimedRotatingFileHandler(log_file[1],
               when=rotate_params[0],
               interval=int(rotate_params[1]),
               backupCount=int(rotate_params[2]))
            logger.addHandler(handler)
            handler.setFormatter(logger_formatter)

LOOP_DURATION=5
if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="CloneSquad Instance watcher")
    parser.add_argument('--api-polling-period', help="Number of seconds between polling of CloneSquad API for status change", 
            nargs='?', type=int, default=argparse.SUPPRESS)
    parser.add_argument('--on-draining-block-new-connections-to-ports', help="Specify a list of ports where, on DRAINING state, to install IPTable rule"
            " to reject new connections (while allowing the current ones to finish)", 
            nargs='*', type=int, default=argparse.SUPPRESS)
    parser.add_argument('--config', help="Configuration file (JSON format)",
            nargs='?', type=str, default=argparse.SUPPRESS)
    parser.add_argument('--script-dir', help="Directory of scripts to launch of instance state change. ",
            nargs='?', type=str, default=argparse.SUPPRESS)
    parser.add_argument('--instance-state', help="Force to consider the specified state as the one for the instance (debug purpose)",
            nargs='?', type=str, default=argparse.SUPPRESS)
    parser.add_argument('--stale-context-timeout', help="Define the period (in seconds) instance meta are considered fresh before to rescan them.",
            nargs='?', type=int, default=argparse.SUPPRESS)
    parser.add_argument('--force', help="Force operations despite lack of pre-requisites (ex: no Targetgroup used).",
            nargs='?', type=bool, default=argparse.SUPPRESS)
    parser.add_argument('--log-file', help="File where to write operation logs.",
            nargs='?', type=str, default=argparse.SUPPRESS)
    parser.add_argument('--log-file-rotate', help="File where to write operation logs. Format: <timeunit>,<interval>,<retention> Default value: h,1,24 meaning rotate every hour and keep 24 log backup (one day).",
            nargs='?', type=str, default=argparse.SUPPRESS)
    parser.add_argument('--generate-systemd', help="Generate a systemd service file at the specified location.",
            nargs='?', type=str, default=argparse.SUPPRESS)
    parser.add_argument('--do-not-generate-systemd', help="Force no generation of systemd file.",
            nargs='?', type=str, default=argparse.SUPPRESS)

    read_configuration()

    if os.getuid() != 0:
        logger.warning("Not running as root user: Can not manage IPTables. --on-draining-block-new-connections-to-ports disabled!")

    while True:
        try:
            loop()
        except KeyboardInterrupt as e:
            sys.exit(1)
        except Exception as e:
            logger.exception(f"Got Exception in main loop: {e}")
        logger.info(f"Waiting {LOOP_DURATION} seconds before next GLOBAL loop...")
        time.sleep(LOOP_DURATION)
