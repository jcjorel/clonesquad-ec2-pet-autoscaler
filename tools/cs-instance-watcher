#!/usr/bin/python3
"""This application is designed to be run of instances managed by CloneSquad.

It is a daemon that poll efficiently the CloneSquad and detect status change. 
On status change, it starts scripts to perform actions.

It contains a common default action that can be enabled on demand:
* Ability to set an IPTable entry on 'draining' state.
"""

import os
import sys
import argparse
import json
import subprocess
import re
import pdb
import time
from datetime import datetime, timezone

# Configure logging
import logging
from logging import handlers
LOG_LEVEL = logging.INFO
logger = logging.getLogger(sys.argv[0])
logger.setLevel(LOG_LEVEL)
logger.propagate = False
ch = logging.StreamHandler()
ch.setLevel(LOG_LEVEL)
logger_formatter = logging.Formatter("[%(levelname)s] %(asctime)s %(filename)s:%(lineno)d - %(message)s")
ch.setFormatter(logger_formatter)
logger.addHandler(ch)

try:
    import requests
except:
    logger.error("Missing critical dependency! Please do 'python3 -m pip install requests requests-iamauth boto3'...")
    sys.exit(1)
try:
    from iamauth import IAMAuth
except:
    logger.error("Missing critical dependency! Please do 'python3 -m pip install requests requests-iamauth boto3'...")
    sys.exit(1)
try:
    import boto3
    from botocore.config import Config
except:
    logger.error("Missing critical dependency! Please do 'python3 -m pip install requests requests-iamauth boto3'...")
    sys.exit(1)

def sys_exec(cmd, silent=False):
    try:
        if not silent:
            logger.info("Exec command: %s" % " ".join(cmd))
        res = subprocess.Popen(cmd, stdout=subprocess.PIPE)
        res.wait() 
    except OSError:
        logger.exception("Failed to execute command: %s" % cmd)
        return None

    if res.returncode != 0:
        logger.error("Executed command %s return a non-zero code: %s" % (cmd, res.returncode))
        return None   
    return str(res.stdout.read(), "utf-8")



def on_draining_block_new_connections_to_ports(instance_stateo, subfleet_name):
    ports  = args["on_draining_block_new_connections_to_ports"]
    if args["instance_state"] != "":
        instance_state = args["instance_state"] # Override
    if instance_state not in ["stopping", "draining"]:
        if len(ports):
            logger.info("Instance not in 'draining' or 'stopping' state (current state is '%s'): No port blacklist." % instance_state)
        ports = [] # When not in draining state, no port are blacklisted
    else:
        logger.info("Configuring 'on_draining_block_new_connections_to_ports' built-in behavior for ports: %s" % ports)
    # Always run an 'iptables -L' to ensure iptables kernel modules are loaded.
    sys_exec(["iptables", "-L"], silent=True)
    output = sys_exec(["iptables-save"], silent=True)
    if output is None:
        log.error("Failed to retrieve iptables-save!")
        return
    iptables          = output.split("\n")
    filter_start_idx  = -1
    filter_commit_idx = -1
    for i in range(0, len(iptables)):
        if iptables[i] == "*filter":
            filter_start_idx = i
        if filter_start_idx != -1 and iptables[i] == "COMMIT":
            filter_commit_idx = i
            break
    if filter_start_idx == -1 or filter_commit_idx == -1:
        logger.error("Can't find '*filter' and/or 'COMMIT' keyword in iptables-save output!")
        return
    filter_table = iptables[filter_start_idx:filter_commit_idx]

    cs_chain_pattern = ":CS-INSTANCE-WATCHER -"
    cs_chain         = next(filter(lambda l: l.startswith(cs_chain_pattern), filter_table), None)
    if len(ports) and cs_chain is None:
        sys_exec(["iptables", "-N", "CS-INSTANCE-WATCHER"])

    send_cs_chain_pattern = "-A INPUT -j CS-INSTANCE-WATCHER"
    send_cs_chain         = next(filter(lambda l: l.startswith(send_cs_chain_pattern), iptables), None)
    if len(ports) and send_cs_chain is None:
        sys_exec(["iptables", "-I", "INPUT", "-j", "CS-INSTANCE-WATCHER"])
    
    rule_pattern   = "-{command} CS-INSTANCE-WATCHER -p tcp -m tcp --dport {port} -m state --state NEW -j REJECT --reject-with icmp-port-unreachable"
    match_var      = {"command":"A", "port":"(\d+)"}
    cs_rules       = [r for r in filter_table if re.match(rule_pattern.format(**match_var), r)]
    existing_ports = []
    for rule in cs_rules:
        m = re.search(rule_pattern.format(**match_var), rule)
        if len(m.groups()) != 1:
            logger.error("Can't parse rule '%s' as expected! Bug??" % rule)
            continue
        existing_ports.append(int(m.group(1)))

    # Remove outdated rules
    outdated_ports = [ r for r in existing_ports if r not in ports ]
    for p in outdated_ports:
        cmd = "iptables %s" % rule_pattern.format(**{"command":"D", "port":p})
        sys_exec(cmd.split())
    # Add missing rules
    missing_ports  = [ r for r in ports if r not in existing_ports ]
    for p in missing_ports:
        cmd = "iptables %s" % rule_pattern.format(**{"command":"A", "port":p})
        sys_exec(cmd.split())

    # If no port configured, suppress also the chain
    if not len(ports):
        if send_cs_chain is not None:
            sys_exec(["iptables", "-D", "INPUT", "-j", "CS-INSTANCE-WATCHER"])
        if cs_chain is not None:
            sys_exec(["iptables", "-X", "CS-INSTANCE-WATCHER"])


def loop():
    start_time = seconds()
    session    = requests.Session()
    try:
        instance_id = str(session.get('http://169.254.169.254/latest/meta-data/instance-id').content, "utf-8")
    except Exception as e:
        logger.exception(f"Failed to fetch current instance Id! (???) : {e}")
        return False
    logger.info(f"Running on instance '{instance_id}'.")
    try:
        os.environ["AWS_DEFAULT_REGION"] = str(session.get('http://169.254.169.254/latest/meta-data/placement/availability-zone').content, "utf-8")[:-1]
    except Exception as e:
        logger.error(f"Failed to fetch current region Id! (???) : {e}")
        return False
    logger.info("Current region: %s" % os.environ["AWS_DEFAULT_REGION"])
    session.auth = IAMAuth() # Make out calls capable to do SigV4 auth.

    config = Config(
       retries = {
       'max_attempts': 5,
       'mode': 'standard'
       })
    sts_client    = boto3.client("sts",    config=config)
    ec2_client    = boto3.client("ec2",    config=config)
    lambda_client = boto3.client("lambda", config=config)

    # Discover the current CloneSquad GroupName
    try:
        Filters   = [{'Name': 'instance-id', 'Values': [instance_id]}]
        response  = ec2_client.describe_instances(Filters=Filters)
        instances = []
        for reservation in response["Reservations"]:
            instances.extend(reservation["Instances"])
        if len(instances) != 1:
            raise Exception(f"Can't describe instance '{instance_id}'! (describe_instances returned %d instances)" % len(instances))
    except Exception as e:
        logger.error(f"Failed to describe instance '{instance_id}' (IAM role issue?)! : {e}")
        return False

    tags       = instances[0]["Tags"]
    tag        = next(filter(lambda t: t["Key"] == "clonesquad:group-name", tags), None)
    if tag is None:
        logger.error(f"Instance '{instance_id}' does not belong to a CloneSquad group! (No 'clonesquad:group-name' tag!)")
        return False
    group_name = tag["Value"]

    # Get the current Account Id
    try:
        account_id = sts_client.get_caller_identity().get('Account')
    except Exception as e:
        logger.error(f"Failed to get current Account Id from STS service (IAM role issue?)! : {e}")
        return False

    # Discover API GW URL
    try:
        response   = lambda_client.invoke(
            FunctionName="arn:aws:lambda:%s:%s:function:CloneSquad-Discovery-%s" % (os.environ["AWS_DEFAULT_REGION"], account_id, group_name),
            InvocationType='RequestResponse',
            LogType='Tail',
            Payload=b""
            )
        payload          = json.loads(str(response["Payload"].read(), "utf-8"))
        logger.info(f"Discovery data: {payload}")
        api_gw_url       = payload["InteractAPIGWUrl"]
        api_gw_id        = payload["InteractApi"]
        vpc_endpoint_dns = payload["ApiGwVpcEndpointDNSEntry"] if "ApiGwVpcEndpointDNSEntry" in payload and payload["ApiGwVpcEndpointDNSEntry"] != "" else None
    except Exception as e:
        logger.error(f"Failed to discover API GW Url!  (IAM role issue?): {e}")
        return False

    while (seconds() - start_time) < args["stale_context_timeout"]:
        last_poll_time = seconds()
        try:
            if vpc_endpoint_dns is not None:
                # If a VPC Endpoint is specified, we prefer it...
                url = "https://%s/v1/metadata" % vpc_endpoint_dns
            else:
                # If not, we use the Public DNS name of the API GW.
                url = "%s/metadata" % api_gw_url
            logger.info(f"Calling API GW URL {url}...")
            api_payload = str(session.get(url, headers={"x-apigw-api-id": f"{api_gw_id}"}).content, "utf-8")
            if api_payload[0] != "{":
                raise ValueError(f"API GW Response not a JSON: '{api_payload}'")
            payload     = json.loads(api_payload)
            if "State" not in payload:
                raise ValueError(f"API GW Response not in an expected JSON format: '{api_payload}'")
        except:
            logger.error(f"Failed to process API GW response! ({url}) [API response={api_payload}]")
            return False
        logger.info(f"Instance metadata: {payload}")
        subfleet_name  = payload["SubfleetName"]

        # When targetgroups are used, we do not need cs-instance-watcher (only in the autoscaled fleet, we always need in subfleet).
        if subfleet_name is None and "TargetGroups" in payload:
            targetgroups = payload["TargetGroups"]
            if targetgroups["NbOfTargetGroups"] and not args["force"]:
                logger.warning(f"Targetgroups are used in group name '{group_name}': No need for cs-instance-watcher! (To force use, set --force option)")
                time.sleep(wait_time)
                break

        instance_state = payload["State"]

        # Call built-in behavior
        on_draining_block_new_connections_to_ports(instance_state, subfleet_name)
        wait_time = max(0, min(60, args["api_polling_period"]) - (seconds() - last_poll_time))
        logger.info("Waiting next polling (%.02fs)..." % wait_time)
        time.sleep(wait_time)

def seconds():
    now   = datetime.now(tz=timezone.utc) 
    epoch = datetime.utcfromtimestamp(0).replace(tzinfo=timezone.utc)
    return (now - epoch).total_seconds()

args = {
    "api_polling_period": 10,
    "on_draining_block_new_connections_to_ports": [],
    "instance_state": "",
    "stale_context_timeout": 300,
    "config": "/etc/cs-instance-watcher.json",
    "force": False
}
LOOP_DURATION=5
if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="CloneSquad Instance watcher")
    parser.add_argument('--api-polling-period', help="Number of seconds between polling of CloneSquad API for status change", 
            nargs='?', type=int, default=argparse.SUPPRESS)
    parser.add_argument('--on-draining-block-new-connections-to-ports', help="Specify a list of ports where, on DRAINING state, to install IPTable rule"
            " to reject new connections (while allowing the current ones to finish)", 
            nargs='*', type=int, default=argparse.SUPPRESS)
    parser.add_argument('--config', help="Configuration file (JSON format)",
            nargs='?', type=str, default=argparse.SUPPRESS)
    parser.add_argument('--instance-state', help="Force to consider the specified state as the one for the instance (debug purpose)",
            nargs='?', type=str, default=argparse.SUPPRESS)
    parser.add_argument('--stale-context-timeout', help="Define the period (in seconds) instance meta are considered fresh before to rescan them.",
            nargs='?', type=int, default=argparse.SUPPRESS)
    parser.add_argument('--force', help="Force operations despite lack of pre-requisites (ex: no Targetgroup used).",
            nargs='?', type=bool, default=argparse.SUPPRESS)
    parser.add_argument('--log-file', help="File where to write operation logs.",
            nargs='?', type=str, default=argparse.SUPPRESS)
    parser.add_argument('--log-file-rotate', help="File where to write operation logs. Format: <timeunit>,<interval>,<retention> Default value: d,1,7 meaning rotate every day and keep 7 log backup (one week).",
            nargs='?', type=str, default=argparse.SUPPRESS)
    parser.add_argument('--generate-systemd', help="Generate a systemd service file at the specified location.",
            nargs='?', type=str, default=argparse.SUPPRESS)
    parser.add_argument('--do-not-generate-systemd', help="Force no generation of systemd file.",
            nargs='?', type=str, default=argparse.SUPPRESS)

    if os.path.exists(args["config"]):
        try:
            c = json.load(args["config"])
            for a in c:
                args[a] = c[a]
        except Exception as e:
            log.error("Failed to read/parse configuration file '%s'! : %s" % (args["config"], e))
            sys.exit(1)

    # Override with command line args
    _args = parser.parse_args()._get_kwargs()
    for a in _args:
        args[a[0]] = a[1]

    generate_systemd       = next(filter(lambda a: a[0] == "generate_systemd", _args), None)
    do_not_generate_systemd = next(filter(lambda a: a[0] == "do_not_generate_systemd", _args), None)
    if generate_systemd and not do_not_generate_systemd:
        cmd = sys.argv[0]
        options = "%s --do-not-generate-systemd" % " ".join(sys.argv[1:])
        with open(generate_systemd[1], "w") as f:
            f.write(f"""
[Unit]
Description=CloneSquad Instance service
After=network.target
StartLimitIntervalSec=0

[Service]
Type=simple
Restart=always
RestartSec=10
ExecStart={cmd} {options}

[Install]
WantedBy=multi-user.target
            """)
        logger.info("Generated systemd file at '%s'." % generate_systemd[1])
        sys.exit(0)

    log_file = next(filter(lambda a: a[0] == "log_file", _args), None)
    if log_file:
        rotate_params = ["d", "1", "7"] # Default value for log rotate
        log_file_rotate = next(filter(lambda a: a[0] == "log_file_rotate", _args), None)
        if log_file_rotate:
            params = log_file_rotate[1].split(",")
            for i in range(0, len(params)):
                rotate_params[i] = params[i]
        logger.info(f"Logging to rotated file '%s' (rotation parameters={rotate_params}). Disabling logging to stdout..." % log_file[1])
        logger.removeHandler(logger.handlers[0])
        handler = handlers.TimedRotatingFileHandler(log_file[1],
           when=rotate_params[0],
           interval=int(rotate_params[1]),
           backupCount=int(rotate_params[2]))
        logger.addHandler(handler)
        handler.setFormatter(logger_formatter)

    while True:
        try:
            loop()
        except KeyboardInterrupt as e:
            sys.exit(1)
        except Exception as e:
            logger.exception(f"Got Exception in main loop: {e}")
        logger.info(f"Waiting {LOOP_DURATION} seconds before next GLOBAL loop...")
        time.sleep(LOOP_DURATION)
