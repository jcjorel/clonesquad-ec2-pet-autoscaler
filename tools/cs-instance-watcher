#!/usr/bin/python3
"""This application is designed to be run of instances managed by CloneSquad.

It is a daemon that poll efficiently the CloneSquad and detect status change. 
On status change, it starts scripts to perform actions.

It contains a common default action that can be enabled on demand:
* Ability to set an IPTable entry on 'draining' state.
"""

import os
import sys
import argparse
import json
import subprocess
import re
import pdb
import time
from datetime import datetime, timezone

# Configure logging
import logging
LOG_LEVEL = logging.INFO
logger = logging.getLogger(sys.argv[0])
logger.setLevel(LOG_LEVEL)
logger.propagate = False
ch = logging.StreamHandler()
ch.setLevel(LOG_LEVEL)
formatter = logging.Formatter("[%(levelname)s] %(asctime)s %(filename)s:%(lineno)d - %(message)s")
ch.setFormatter(formatter)
logger.addHandler(ch)

try:
    import requests
except:
    logger.error("Missing critical dependency! Please do 'pip install requests'...")
    sys.exit(1)
try:
    from iamauth import IAMAuth
except:
    logger.error("Missing critical dependency! Please do 'pip install requests-iamauth'...")
    sys.exit(1)
try:
    import boto3
    from botocore.config import Config
except:
    logger.error("Missing critical dependency! Please do 'pip install boto3'...")
    sys.exit(1)

def sys_exec(cmd, silent=False):
    try:
        if not silent:
            logger.info("Exec command: %s" % " ".join(cmd))
        res = subprocess.Popen(cmd, stdout=subprocess.PIPE)
        res.wait() 
    except OSError:
        logger.exception("Failed to execute command: %s" % cmd)
        return None

    if res.returncode != 0:
        logger.error("Executed command %s return a non-zero code: %s" % (cmd, res.returncode))
        return None   
    return str(res.stdout.read(), "utf-8")



def on_draining_block_new_connections_to_ports(instance_state):
    ports  = args["on_draining_block_new_connections_to_ports"]
    if args["instance_state"] != "":
        instance_state = args["instance_state"] # Override
    if instance_state != "draining":
        if len(ports):
            logger.info("Instance not in 'draining' state (currently '%s'): No port blacklist." % instance_state)
        ports = [] # When not in draining state, no port are blacklisted
    else:
        logger.info("Configuring 'on_draining_block_new_connections_to_ports' built-in behavior for ports: %s" % ports)
    output = sys_exec(["iptables-save"], silent=True)
    if output is None:
        log.error("Failed to retrieve iptables-save!")
        return
    iptables          = output.split("\n")
    filter_start_idx  = -1
    filter_commit_idx = -1
    for i in range(0, len(iptables)):
        if iptables[i] == "*filter":
            filter_start_idx = i
        if filter_start_idx != -1 and iptables[i] == "COMMIT":
            filter_commit_idx = i
            break
    if filter_start_idx == -1 or filter_commit_idx == -1:
        logger.error("Can't find '*filter' and/or 'COMMIT' keyword in iptables-save output!")
        return
    filter_table = iptables[filter_start_idx:filter_commit_idx]

    cs_chain_pattern = ":CS-INSTANCE-WATCHER -"
    cs_chain         = next(filter(lambda l: l.startswith(cs_chain_pattern), filter_table), None)
    if len(ports) and cs_chain is None:
        sys_exec(["iptables", "-N", "CS-INSTANCE-WATCHER"])

    send_cs_chain_pattern = "-A INPUT -j CS-INSTANCE-WATCHER"
    send_cs_chain         = next(filter(lambda l: l.startswith(send_cs_chain_pattern), iptables), None)
    if len(ports) and send_cs_chain is None:
        sys_exec(["iptables", "-I", "INPUT", "-j", "CS-INSTANCE-WATCHER"])
    
    rule_pattern   = "-{command} CS-INSTANCE-WATCHER -p tcp -m tcp --dport {port} -m state --state NEW -j REJECT --reject-with icmp-port-unreachable"
    match_var      = {"command":"A", "port":"(\d+)"}
    cs_rules       = [r for r in filter_table if re.match(rule_pattern.format(**match_var), r)]
    existing_ports = []
    for rule in cs_rules:
        m = re.search(rule_pattern.format(**match_var), rule)
        if len(m.groups()) != 1:
            logger.error("Can't parse rule '%s' as expected! Bug??" % rule)
            continue
        existing_ports.append(int(m.group(1)))

    # Remove outdated rules
    outdated_ports = [ r for r in existing_ports if r not in ports ]
    for p in outdated_ports:
        cmd = "iptables %s" % rule_pattern.format(**{"command":"D", "port":p})
        sys_exec(cmd.split())
    # Add missing rules
    missing_ports  = [ r for r in ports if r not in existing_ports ]
    for p in missing_ports:
        cmd = "iptables %s" % rule_pattern.format(**{"command":"A", "port":p})
        sys_exec(cmd.split())

    # If no port configured, suppress also the chain
    if not len(ports):
        if send_cs_chain is not None:
            sys_exec(["iptables", "-D", "INPUT", "-j", "CS-INSTANCE-WATCHER"])
        if cs_chain is not None:
            sys_exec(["iptables", "-X", "CS-INSTANCE-WATCHER"])


def loop():
    start_time = seconds()
    session    = requests.Session()
    try:
        instance_id = str(session.get('http://169.254.169.254/latest/meta-data/instance-id').content, "utf-8")
    except Exception as e:
        logger.exception("Failed to fetch current instance Id! (???) : %s" % e)
        return False
    logger.info("Running on instance '%s'." % instance_id)
    try:
        os.environ["AWS_DEFAULT_REGION"] = str(session.get('http://169.254.169.254/latest/meta-data/placement/availability-zone').content, "utf-8")[:-1]
    except Exception as e:
        logger.error("Failed to fetch current region Id! (???) : %s" % e)
        return False
    logger.info("Current region: %s" % os.environ["AWS_DEFAULT_REGION"])
    session.auth = IAMAuth() # Make out calls capable to do SigV4 auth.

    config = Config(
       retries = {
       'max_attempts': 5,
       'mode': 'standard'
       })
    sts_client    = boto3.client("sts",    config=config)
    ec2_client    = boto3.client("ec2",    config=config)
    lambda_client = boto3.client("lambda", config=config)

    # Discover the current CloneSquad GroupName
    try:
        Filters   = [{'Name': 'instance-id', 'Values': [instance_id]}]
        response  = ec2_client.describe_instances(Filters=Filters)
        instances = []
        for reservation in response["Reservations"]:
            instances.extend(reservation["Instances"])
        if len(instances) != 1:
            raise Exception("Can't describe instance '%s'! (describe_instances returned %d instances)" % (instance_id, len(instances)))
    except Exception as e:
        logger.error("Failed to describe instance '%d'! : %s" % (instance_id, e))
        return False

    tags       = instances[0]["Tags"]
    tag        = next(filter(lambda t: t["Key"] == "clonesquad:group-name", tags), None)
    if tag is None:
        logger.error("Instance '%s' does not belong to a CloneSquad group! (No 'clonesquad:group-name' tag!)" % instance_id)
        return False
    group_name = tag["Value"]

    # Get the current Account Id
    try:
        account_id = sts_client.get_caller_identity().get('Account')
    except Exception as e:
        logger.error("Failed to get current region from STS service! : %s" % e)
        return False

    # Discover API GW URL
    try:
        response   = lambda_client.invoke(
            FunctionName="arn:aws:lambda:%s:%s:function:CloneSquad-Discovery-%s" % (os.environ["AWS_DEFAULT_REGION"], account_id, group_name),
            InvocationType='RequestResponse',
            LogType='Tail',
            Payload=b""
            )
        payload    = json.loads(str(response["Payload"].read(), "utf-8"))
        logger.info("Discovery data: %s" % payload)
        api_gw_url = payload["InteractAPIGWUrl"]
    except Exception as e:
        logger.error("Failed to discover API GW Url!")
        return False

    while (seconds() - start_time) < args["stale_context_timeout"]:
        last_poll_time = seconds()
        try:
            logger.info("Calling %s/metadata..." % api_gw_url)
            api_payload = str(session.get("%s/metadata" % api_gw_url).content, "utf-8")
            if api_payload[0] != "{":
                raise ValueError("API GW Response not a JSON: '%s'" % api_payload)
            payload     = json.loads(api_payload)
        except:
            logger.exception("Failed to process API GW response! (%s) [API response=%s]" % (api_gw_url, api_payload))
            return False
        logger.info("Instance metadata: %s" % payload)
        instance_state = payload["State"]

        # Call built-in behavior
        on_draining_block_new_connections_to_ports(instance_state)
        wait_time = max(0, args["api-polling-period"] - (seconds() - last_poll_time))
        logger.info("Waiting next polling (%.02fs)..." % wait_time)
        time.sleep(wait_time)

def seconds():
    now   = datetime.now(tz=timezone.utc) 
    epoch = datetime.utcfromtimestamp(0).replace(tzinfo=timezone.utc)
    return (now - epoch).total_seconds()

args = {}
LOOP_DURATION=5
if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="CloneSquad configuration documentation generator")
    parser.add_argument('api-polling-period', help="Number of seconds between polling of CloneSquad API for status change", 
            nargs='?', type=int, default=10)
    parser.add_argument('--on-draining-block-new-connections-to-ports', help="Specify a list of ports where, on DRAINING state, to install IPTable rule"
            " to reject new connections (while allowing the current ones to finish)", 
            nargs='*', type=int, default=[])
    parser.add_argument('--instance-state', help="Force to consider the specified state as the one for the instance (debug purpose)",
            nargs='?', type=str, default="")
    parser.add_argument('--stale-context-timeout', help="Define the period (in seconds) instance meta are considered fresh before to rescan them.",
            nargs='?', type=int, default=300)

    for a in parser.parse_args()._get_kwargs():
        args[a[0]] = a[1]

    while True:
        try:
            loop()
        except Exception as e:
            logger.exception("Got Exception in main loop: %s" % e)
        logger.info("Waiting %d seconds before next GLOBAL loop..." % LOOP_DURATION)
        time.sleep(LOOP_DURATION)
