#!/usr/bin/python3
#
import os
import sys
import json
import pdb
import argparse
import logging
import datetime
from collections import defaultdict
from logging import handlers
log = logging.getLogger(sys.argv[0])
log.setLevel(logging.INFO)

parser = argparse.ArgumentParser(description="Athena DDL Generator")
parser.add_argument('input_file', help="Input file (JSON).", type=str, nargs=1)
parser.add_argument('--s3-url', '-s', help="Target S3 (s3://... format)", type=str, default="")
parser.add_argument('--extra-ddl-parameter', '-x', help="Extra string to add to the generated DDL statement.", type=str, default="")

args = parser.parse_args()

input_file  = open(args.input_file[0])
input_lines = input_file.readlines()

json_lines  = []
i           = 0
for l in input_lines:
    i += 1
    try:
        json_lines.append(json.loads(l))
    except Exception as e:
        log.warning(f"Can not decode line {i} as JSON document!")    

def is_date(d):
    try:
        return datetime.datetime.strptime(d, '%Y-%m-%d %H:%M:%S.%f') is not None
    except:
        try:
            return datetime.datetime.strptime(d, '%Y-%m-%d %H:%M:%S') is not None
        except:
            return False

def encode_json(document, outputs):
    d = {}
    for k in document:
        if k is None:
            log.error("Can not encode Null parameter!")
            sys.exit(1)
        v    = document[k]
        item = {}
        if isinstance(v, dict):
            encode_json(v, item)
            d[k] = item
        elif isinstance(v, list):
            d[k] = [str]
            if len(v):
                if isinstance(v[0], dict):
                    it = {}
                    encode_json(v[0], it)
                    d[k] = [it]
                else:
                    if is_date(v[0]):
                        d[k] = [datetime.datetime]
                    else:
                        d[k] = [v[0].__class__]
        else:
            if is_date(v):
                item = datetime.datetime
            else:
                item = v.__class__
            d[k] = item
    outputs.update(d)

def process_documents(inputs, outputs):
    for l in inputs:
        if not isinstance(l, dict):
            log.warning(f"JSON document must be a Dict! Ignoring")
            continue
        encode_json(l, outputs)

def output_ddl(v, node, depth, output):
        justify = "".ljust(4 * depth)
        if node is not None and node != "":
            node += ":"
        o = []
        if isinstance(v, dict):
            if node is not None:
                output.append(f"{justify}{node}struct<")
            keys = sorted(v.keys())
            for k in keys:
                output_ddl(v[k], k, depth + 1, o)
            if node is not None:
                output.append(f"{justify}    >")
        if isinstance(v, list):
            o.append(f"{justify}{node}array<")
            for l in v:
                output_ddl(l, "", depth + 1, output)
            o.append(f"{justify}    >")
        if v == dict:
            o.append(f"{justify}{node}struct<>")
        if v == str:
            o.append(f"{justify}{node}string")
        if v == bool:
            o.append(f"{justify}{node}bool")
        if v == int:
            o.append(f"{justify}{node}int")
        if v == float:
            o.append(f"{justify}{node}float")
        if v == datetime.datetime:
            o.append(f"{justify}{node}timestamp")
        output.append(",\n".join(o))


        
document = {}
process_documents(json_lines, document)
output = []
pdb.set_trace()
output_ddl(document, None, 4, output)
print("\n".join(output))


